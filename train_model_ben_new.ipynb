{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24773cdc-4bbe-48c3-9910-8b39c38bfc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 16:35:49.435268: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from qkeras import *\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "pi = 3.14159265359\n",
    "\n",
    "maxval=1e9\n",
    "minval=1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac065e8-fcf2-44a0-8dee-e1e44e605137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from dataprep import *\n",
    "from OptimizedDataGeneratorNew import OptimizedDataGenerator\n",
    "from loss import *\n",
    "from models import *\n",
    "# import mdmm\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff499d81-383f-4988-94d7-12815179e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfbc64d0-998a-4022-b4f5-e886c4c07941",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_dir = \"/uscms/home/bweiss/nobackup/smart-pixels/\"\n",
    "tfrecords_base_dir = os.path.join(dataset_base_dir, \"tfrecords\")\n",
    "\n",
    "# dataset_dir_train = os.path.join(dataset_base_dir, \"dataset3src_50x12p5\", 'mean_filt', 'train')\n",
    "# dataset_dir_val = os.path.join(dataset_base_dir, \"dataset3src_50x12p5\", 'mean_filt', 'test')\n",
    "\n",
    "# tfrecords_dir_train = os.path.join(tfrecords_base_dir, \"TFR_train\",'3src_MeanFilt3_133eThresh')\n",
    "# tfrecords_dir_val   = os.path.join(tfrecords_base_dir, \"TFR_val\",'3src_MeanFilt3_133eThresh')\n",
    "\n",
    "dataset_dir_train = os.path.join(dataset_base_dir, \"dataset_3sr_16x16_50x12P5_parquets\", 'train')\n",
    "dataset_dir_val = os.path.join(dataset_base_dir, \"dataset_3sr_16x16_50x12P5_parquets\", 'test')\n",
    "\n",
    "tfrecords_dir_train = os.path.join(tfrecords_base_dir, \"TFR_train\",'3sr_16x16')\n",
    "tfrecords_dir_val   = os.path.join(tfrecords_base_dir, \"TFR_val\",'3sr_16x16')\n",
    "\n",
    "# dataset_dir_train = os.path.join(dataset_base_dir, \"dataset_2s_50x12P5_parquets\", 'shuffled')\n",
    "# dataset_dir_val = os.path.join(dataset_base_dir, \"dataset3src_50x12p5\", 'test')\n",
    "\n",
    "# tfrecords_dir_train = os.path.join(tfrecords_base_dir, \"TFR_train\",'dataset_2s_50x12P5_OG_shuffled')\n",
    "# tfrecords_dir_val   = os.path.join(tfrecords_base_dir, \"TFR_val\",'dataset_2s_50x12P5_OG_shuffled')\n",
    "\n",
    "\n",
    "# tfrecords_dir_train = os.path.join(tfrecords_base_dir, \"TFR_train\",'2TS_OG')\n",
    "# tfrecords_dir_val   = os.path.join(tfrecords_base_dir, \"TFR_val\",'2TS_OG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c17a48-9308-40e4-a126-5478659cfedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(dataset_dir_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af8bb9b7-c75e-489d-83bc-ad517c652aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "val_batch_size = 5000\n",
    "train_file_size = 80\n",
    "val_file_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66491533-15ba-4337-917e-8f99508cf3bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /uscms/home/bweiss/nobackup/smart-pixels/tfrecords/TFR_val/3sr_16x16 is removed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files...: 100%|██████████| 20/20 [00:06<00:00,  2.88it/s]\n",
      "Saving batches as TFRecords: 100%|██████████| 78/78 [00:14<00:00,  5.30it/s]\n",
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Validation generator 22.215576171875 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "validation_generator = OptimizedDataGenerator(\n",
    "    dataset_base_dir = dataset_dir_train,\n",
    "    file_type = \"parquet\",\n",
    "    data_format = \"3D\",\n",
    "    batch_size = val_batch_size,\n",
    "    file_count = val_file_size,\n",
    "    to_standardize= True,\n",
    "    include_y_local= False,\n",
    "    labels_list = ['x-midplane','y-midplane','cotAlpha','cotBeta'],\n",
    "    input_shape = (2,16,16), # (20,13,21),\n",
    "    transpose = (0,2,3,1),\n",
    "    shuffle = False, \n",
    "    files_from_end=True,\n",
    "\n",
    "    tfrecords_dir = tfrecords_dir_val,\n",
    "    use_time_stamps = [0, 19], #-1\n",
    "    noise = -1,\n",
    "    select_contained = False,\n",
    "    max_workers = 2\n",
    ")\n",
    "\n",
    "print(\"--- Validation generator %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# validation_generator.debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5b445b8-3e36-43b9-837b-95124e181923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(validation_generator[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dccba057-7aa7-4b85-95bd-8977c14cf7ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /uscms/home/bweiss/nobackup/smart-pixels/tfrecords/TFR_train/3sr_16x16 does not exist and cannot be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files...: 100%|██████████| 80/80 [00:35<00:00,  2.29it/s]\n",
      "Saving batches as TFRecords: 100%|██████████| 83/83 [00:25<00:00,  3.23it/s]\n",
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training generator 61.4472291469574 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# training generator\n",
    "start_time = time.time()\n",
    "training_generator = OptimizedDataGenerator(\n",
    "    dataset_base_dir = dataset_dir_train,\n",
    "    file_type = \"parquet\",\n",
    "    data_format = \"3D\",\n",
    "    batch_size = batch_size,\n",
    "    file_count = train_file_size,\n",
    "    to_standardize= True,\n",
    "    include_y_local= False,\n",
    "    labels_list = ['x-midplane','y-midplane','cotAlpha','cotBeta'],\n",
    "    input_shape = (2,16,16), # (20,13,21),\n",
    "    transpose = (0,2,3,1),\n",
    "    shuffle = False, # True \n",
    "\n",
    "    tfrecords_dir = tfrecords_dir_train,\n",
    "    use_time_stamps = [0, 19], #-1\n",
    "    noise = -1,\n",
    "    select_contained = True,\n",
    "    max_workers = 2\n",
    ")\n",
    "print(\"--- Training generator %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "248e5d17-2a8f-4e8c-871a-65a0ab3794b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n",
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n"
     ]
    }
   ],
   "source": [
    "training_generator = OptimizedDataGenerator(\n",
    "    load_from_tfrecords_dir = tfrecords_dir_train,\n",
    "    shuffle = False,\n",
    "    seed = 13,\n",
    "    quantize = False\n",
    ")\n",
    "\n",
    "validation_generator = OptimizedDataGenerator(\n",
    "    load_from_tfrecords_dir = tfrecords_dir_val,\n",
    "    shuffle = False,\n",
    "    seed = 13,\n",
    "    quantize = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c9b8ee3-f02f-4a0a-af31-4cfa3ccdaef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 13:52:04.850536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:52:04.889892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:52:04.890356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:52:04.891535: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-13 13:52:04.897532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:52:04.897823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:52:04.898110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:52:05.000440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:52:05.000788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:52:05.001040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:52:05.001334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38660 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 4g.40gb, pci bus id: 0000:06:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.33888975 -0.36827895  0.21131036 -0.48437527]\n",
      " [ 0.35810393 -0.07309517 -0.15779756 -2.5628595 ]\n",
      " [-0.7434732   0.8028412   0.73284084 -2.6053388 ]\n",
      " ...\n",
      " [ 0.20091476  0.46394742 -1.0701375  -1.1706002 ]\n",
      " [ 0.33557263  0.890665    0.6470125  -2.3743002 ]\n",
      " [-0.13836396  0.2733314   1.0113549  -1.2698406 ]], shape=(5000, 4), dtype=float32)\n",
      "0.77552617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fbc2803e9d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "n=0\n",
    "\n",
    "cluster = validation_generator[0]\n",
    "# print(np.max(cluster[0].numpy()))\n",
    "print(cluster[1])\n",
    "cluster=cluster[0][:,:,:,1]\n",
    "\n",
    "print(np.max(cluster.numpy()))\n",
    "\n",
    "fig,ax = plt.subplots(2,1)\n",
    "h = ax[0].imshow(cluster[n])\n",
    "fig.colorbar(h)\n",
    "\n",
    "# print(cl\n",
    "\n",
    "# def MeanFilter(shape, pool_size, thresh=False):\n",
    "\n",
    "#     inputs = Input(shape=(*shape,1), name=\"input\")\n",
    "    \n",
    "#     x = keras.layers.AveragePooling2D(pool_size=(pool_size, pool_size), \n",
    "#                                       strides = (1, 1), \n",
    "#                                       padding = \"same\",\n",
    "#                                       #data_format = \"channels_first\"\n",
    "#                                      )(inputs)\n",
    "#     if thresh:\n",
    "#             apply_thresh = lambda x: tf.where(x < thresh, tf.zeros_like(x), x)\n",
    "#             x = Lambda(function=apply_thresh)(x)\n",
    "#     outputs = x\n",
    "#     model = Model(inputs=inputs, outputs=outputs)\n",
    "#     return model\n",
    "\n",
    "# shape= (13,21)\n",
    "# model3_thresh = MeanFilter(shape, 3, thresh = 0.42777381797685826\n",
    "#                           )\n",
    "\n",
    "# model3_thresh.summary()\n",
    "# filter3_thresh= model3_thresh.predict(cluster)\n",
    "# h=ax[1].imshow(filter3_thresh[n,:,:])\n",
    "# fig.colorbar(h)\n",
    "\n",
    "# h = ax[1].imshow(cluster)\n",
    "# fig.colorbar(h)\n",
    "\n",
    "# print(training_generator.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c72cef1b-61db-489f-83bb-039a46861094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 13:57:33.243126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:57:33.281921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:57:33.282281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:57:33.283158: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-13 13:57:33.288718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:57:33.288995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:57:33.289288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:57:33.382286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:57:33.382631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:57:33.382875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-13 13:57:33.383166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38660 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 4g.40gb, pci bus id: 0000:06:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 13, 21, 2)]       0         \n",
      "                                                                 \n",
      " q_separable_conv2d (QSepara  (None, 9, 17, 5)         65        \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " q_activation (QActivation)  (None, 9, 17, 5)          0         \n",
      "                                                                 \n",
      " q_conv2d (QConv2D)          (None, 9, 17, 5)          30        \n",
      "                                                                 \n",
      " q_activation_1 (QActivation  (None, 9, 17, 5)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 3, 5, 5)          0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " q_activation_2 (QActivation  (None, 3, 5, 5)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 75)                0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 16)                1216      \n",
      "                                                                 \n",
      " q_activation_3 (QActivation  (None, 16)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " q_dense_1 (QDense)          (None, 16)                272       \n",
      "                                                                 \n",
      " q_activation_4 (QActivation  (None, 16)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " q_dense_2 (QDense)          (None, 14)                238       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,821\n",
      "Trainable params: 1,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=CreateModel((13,21,2),n_filters=5,pool_size=3, conv_kernel_size=5 #mean_filter=3, thresh=0.6290114754408346\n",
    "                 )\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3),\n",
    "    loss=custom_loss\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce60b630-5e1e-41cd-b9a0-7e9a06e9a395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "fingerprint = '%08x' % random.randrange(16**8)\n",
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "os.makedirs(\"trained_models\", exist_ok=True)\n",
    "training_name = '3src_MeanFilt3_133eThresh_preDG'\n",
    "base_dir = f'./trained_models/model-{fingerprint}-{training_name}-checkpoints'\n",
    "os.makedirs(base_dir, exist_ok=True)  \n",
    "checkpoint_filepath = base_dir + '/weights.{epoch:02d}-t{loss:.2f}-v{val_loss:.2f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ccc68b0-0d5a-4b14-bebc-0d8e6923e178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372eef38\n"
     ]
    }
   ],
   "source": [
    "print(fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd97cbbf-a137-4a5c-9796-11de00abfa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, Callback\n",
    "\n",
    "early_stopping_patience = 50\n",
    "\n",
    "class CustomModelCheckpoint(ModelCheckpoint):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        checkpoints = [f for f in os.listdir(base_dir) if f.startswith('weights')]\n",
    "        # .sort() does not order weight file strings numerically\n",
    "        if len(checkpoints) > 1:\n",
    "            checkpoints.sort(key=lambda x: os.path.getmtime(os.path.join(base_dir,x)))\n",
    "            for checkpoint in checkpoints[:-1]:\n",
    "                os.remove(os.path.join(base_dir, checkpoint))\n",
    "\n",
    "es = EarlyStopping(patience=early_stopping_patience, restore_best_weights=True)\n",
    "\n",
    "mcp = CustomModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_freq='epoch',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(f'{base_dir}/training_log.csv', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d3ecb0d-5db2-4610-bd58-e55d06f049a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1/93 [..............................] - ETA: 3:30 - loss: 103435.2734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 13:58:24.327124: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-06-13 13:58:24.348761: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8800\n",
      "2025-06-13 13:58:24.374632: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x558c795f21a0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - ETA: 0s - loss: 35659.9805\n",
      "Epoch 1: val_loss improved from inf to 16441.68164, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.01-t35659.98-v16441.68.hdf5\n",
      "93/93 [==============================] - 10s 88ms/step - loss: 35659.9805 - val_loss: 16441.6816\n",
      "Epoch 2/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 15510.9150\n",
      "Epoch 2: val_loss improved from 16441.68164 to 13977.23926, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.02-t15510.92-v13977.24.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 15510.9150 - val_loss: 13977.2393\n",
      "Epoch 3/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 13141.5811\n",
      "Epoch 3: val_loss improved from 13977.23926 to 11718.59375, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.03-t13141.58-v11718.59.hdf5\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 13141.5811 - val_loss: 11718.5938\n",
      "Epoch 4/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 11097.7148\n",
      "Epoch 4: val_loss improved from 11718.59375 to 10247.95996, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.04-t11097.71-v10247.96.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 11097.7148 - val_loss: 10247.9600\n",
      "Epoch 5/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 10131.2705\n",
      "Epoch 5: val_loss improved from 10247.95996 to 9266.09961, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.05-t10131.27-v9266.10.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 10131.2705 - val_loss: 9266.0996\n",
      "Epoch 6/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 9311.8594\n",
      "Epoch 6: val_loss improved from 9266.09961 to 8741.34766, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.06-t9311.86-v8741.35.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 9311.8594 - val_loss: 8741.3477\n",
      "Epoch 7/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 9365.2188\n",
      "Epoch 7: val_loss did not improve from 8741.34766\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 9365.2188 - val_loss: 8956.2998\n",
      "Epoch 8/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 9361.8408\n",
      "Epoch 8: val_loss did not improve from 8741.34766\n",
      "93/93 [==============================] - 7s 74ms/step - loss: 9361.8408 - val_loss: 8873.7969\n",
      "Epoch 9/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 8788.9316\n",
      "Epoch 9: val_loss improved from 8741.34766 to 8418.61621, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.09-t8788.93-v8418.62.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 8788.9316 - val_loss: 8418.6162\n",
      "Epoch 10/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 8447.5830\n",
      "Epoch 10: val_loss improved from 8418.61621 to 8168.05322, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.10-t8447.58-v8168.05.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 8447.5830 - val_loss: 8168.0532\n",
      "Epoch 11/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 8165.4185\n",
      "Epoch 11: val_loss improved from 8168.05322 to 7905.92383, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.11-t8165.42-v7905.92.hdf5\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 8165.4185 - val_loss: 7905.9238\n",
      "Epoch 12/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 7983.5630\n",
      "Epoch 12: val_loss improved from 7905.92383 to 7546.45898, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.12-t7983.56-v7546.46.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 7983.5630 - val_loss: 7546.4590\n",
      "Epoch 13/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 7783.4336\n",
      "Epoch 13: val_loss improved from 7546.45898 to 7380.36230, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.13-t7783.43-v7380.36.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 7783.4336 - val_loss: 7380.3623\n",
      "Epoch 14/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 7673.2256\n",
      "Epoch 14: val_loss improved from 7380.36230 to 7271.39990, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.14-t7673.23-v7271.40.hdf5\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 7673.2256 - val_loss: 7271.3999\n",
      "Epoch 15/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 7509.5005\n",
      "Epoch 15: val_loss improved from 7271.39990 to 7118.07910, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.15-t7509.50-v7118.08.hdf5\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 7509.5005 - val_loss: 7118.0791\n",
      "Epoch 16/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 7228.0156\n",
      "Epoch 16: val_loss improved from 7118.07910 to 7013.71191, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.16-t7228.02-v7013.71.hdf5\n",
      "93/93 [==============================] - 7s 75ms/step - loss: 7228.0156 - val_loss: 7013.7119\n",
      "Epoch 17/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 7947.7749\n",
      "Epoch 17: val_loss did not improve from 7013.71191\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 7947.7749 - val_loss: 7420.3086\n",
      "Epoch 18/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 7245.8267\n",
      "Epoch 18: val_loss improved from 7013.71191 to 6926.31006, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.18-t7245.83-v6926.31.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 7245.8267 - val_loss: 6926.3101\n",
      "Epoch 19/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 7238.0913\n",
      "Epoch 19: val_loss did not improve from 6926.31006\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 7238.0913 - val_loss: 6977.7959\n",
      "Epoch 20/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 7247.2593\n",
      "Epoch 20: val_loss improved from 6926.31006 to 6914.44775, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.20-t7247.26-v6914.45.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 7247.2593 - val_loss: 6914.4478\n",
      "Epoch 21/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 7089.0400\n",
      "Epoch 21: val_loss improved from 6914.44775 to 6821.63867, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.21-t7089.04-v6821.64.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 7089.0400 - val_loss: 6821.6387\n",
      "Epoch 22/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6995.8477\n",
      "Epoch 22: val_loss improved from 6821.63867 to 6708.02588, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.22-t6995.85-v6708.03.hdf5\n",
      "93/93 [==============================] - 7s 75ms/step - loss: 6995.8477 - val_loss: 6708.0259\n",
      "Epoch 23/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6812.8716\n",
      "Epoch 23: val_loss improved from 6708.02588 to 6534.30469, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.23-t6812.87-v6534.30.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 6812.8716 - val_loss: 6534.3047\n",
      "Epoch 24/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6708.5083\n",
      "Epoch 24: val_loss did not improve from 6534.30469\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 6708.5083 - val_loss: 6571.0659\n",
      "Epoch 25/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6707.0918\n",
      "Epoch 25: val_loss improved from 6534.30469 to 6437.56396, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.25-t6707.09-v6437.56.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 6707.0918 - val_loss: 6437.5640\n",
      "Epoch 26/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6676.8291\n",
      "Epoch 26: val_loss improved from 6437.56396 to 6421.87451, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.26-t6676.83-v6421.87.hdf5\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 6676.8291 - val_loss: 6421.8745\n",
      "Epoch 27/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6695.4121\n",
      "Epoch 27: val_loss improved from 6421.87451 to 6385.34668, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.27-t6695.41-v6385.35.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 6695.4121 - val_loss: 6385.3467\n",
      "Epoch 28/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6597.0562\n",
      "Epoch 28: val_loss did not improve from 6385.34668\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 6597.0562 - val_loss: 6402.1177\n",
      "Epoch 29/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6539.1211\n",
      "Epoch 29: val_loss improved from 6385.34668 to 6352.19336, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.29-t6539.12-v6352.19.hdf5\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 6539.1211 - val_loss: 6352.1934\n",
      "Epoch 30/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6482.6616\n",
      "Epoch 30: val_loss improved from 6352.19336 to 6329.06152, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.30-t6482.66-v6329.06.hdf5\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 6482.6616 - val_loss: 6329.0615\n",
      "Epoch 31/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6512.5723\n",
      "Epoch 31: val_loss improved from 6329.06152 to 6281.62891, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.31-t6512.57-v6281.63.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 6512.5723 - val_loss: 6281.6289\n",
      "Epoch 32/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6478.1030\n",
      "Epoch 32: val_loss improved from 6281.62891 to 6189.45801, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.32-t6478.10-v6189.46.hdf5\n",
      "93/93 [==============================] - 7s 80ms/step - loss: 6478.1030 - val_loss: 6189.4580\n",
      "Epoch 33/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6440.7676\n",
      "Epoch 33: val_loss did not improve from 6189.45801\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 6440.7676 - val_loss: 6196.6426\n",
      "Epoch 34/500\n",
      "92/93 [============================>.] - ETA: 0s - loss: 6390.9502\n",
      "Epoch 34: val_loss improved from 6189.45801 to 6160.62549, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.34-t6371.27-v6160.63.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 6371.2729 - val_loss: 6160.6255\n",
      "Epoch 35/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6360.4536\n",
      "Epoch 35: val_loss did not improve from 6160.62549\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 6360.4536 - val_loss: 6186.0254\n",
      "Epoch 36/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6321.2388\n",
      "Epoch 36: val_loss improved from 6160.62549 to 6062.26807, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.36-t6321.24-v6062.27.hdf5\n",
      "93/93 [==============================] - 8s 82ms/step - loss: 6321.2388 - val_loss: 6062.2681\n",
      "Epoch 37/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6235.1206\n",
      "Epoch 37: val_loss improved from 6062.26807 to 5904.15234, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.37-t6235.12-v5904.15.hdf5\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 6235.1206 - val_loss: 5904.1523\n",
      "Epoch 38/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6170.6074\n",
      "Epoch 38: val_loss improved from 5904.15234 to 5880.55713, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.38-t6170.61-v5880.56.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 6170.6074 - val_loss: 5880.5571\n",
      "Epoch 39/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6100.2056\n",
      "Epoch 39: val_loss did not improve from 5880.55713\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 6100.2056 - val_loss: 6024.4126\n",
      "Epoch 40/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6022.7246\n",
      "Epoch 40: val_loss improved from 5880.55713 to 5779.07617, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.40-t6022.72-v5779.08.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 6022.7246 - val_loss: 5779.0762\n",
      "Epoch 41/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5954.1455\n",
      "Epoch 41: val_loss improved from 5779.07617 to 5682.94238, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.41-t5954.15-v5682.94.hdf5\n",
      "93/93 [==============================] - 8s 88ms/step - loss: 5954.1455 - val_loss: 5682.9424\n",
      "Epoch 42/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6085.9023\n",
      "Epoch 42: val_loss did not improve from 5682.94238\n",
      "93/93 [==============================] - 8s 82ms/step - loss: 6085.9023 - val_loss: 6148.6689\n",
      "Epoch 43/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6113.5005\n",
      "Epoch 43: val_loss did not improve from 5682.94238\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 6113.5005 - val_loss: 5693.3838\n",
      "Epoch 44/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5973.7671\n",
      "Epoch 44: val_loss did not improve from 5682.94238\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 5973.7671 - val_loss: 5701.4097\n",
      "Epoch 45/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5881.6504\n",
      "Epoch 45: val_loss improved from 5682.94238 to 5481.92871, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.45-t5881.65-v5481.93.hdf5\n",
      "93/93 [==============================] - 8s 80ms/step - loss: 5881.6504 - val_loss: 5481.9287\n",
      "Epoch 46/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5773.1475\n",
      "Epoch 46: val_loss did not improve from 5481.92871\n",
      "93/93 [==============================] - 7s 80ms/step - loss: 5773.1475 - val_loss: 5560.9399\n",
      "Epoch 47/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5727.2676\n",
      "Epoch 47: val_loss improved from 5481.92871 to 5473.14209, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.47-t5727.27-v5473.14.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 5727.2676 - val_loss: 5473.1421\n",
      "Epoch 48/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5641.0527\n",
      "Epoch 48: val_loss improved from 5473.14209 to 5409.68066, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.48-t5641.05-v5409.68.hdf5\n",
      "93/93 [==============================] - 8s 87ms/step - loss: 5641.0527 - val_loss: 5409.6807\n",
      "Epoch 49/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5412.3823\n",
      "Epoch 49: val_loss improved from 5409.68066 to 5150.31104, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.49-t5412.38-v5150.31.hdf5\n",
      "93/93 [==============================] - 9s 93ms/step - loss: 5412.3823 - val_loss: 5150.3110\n",
      "Epoch 50/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5343.3354\n",
      "Epoch 50: val_loss improved from 5150.31104 to 5101.59326, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.50-t5343.34-v5101.59.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 5343.3354 - val_loss: 5101.5933\n",
      "Epoch 51/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5401.2129\n",
      "Epoch 51: val_loss did not improve from 5101.59326\n",
      "93/93 [==============================] - 7s 80ms/step - loss: 5401.2129 - val_loss: 6502.9229\n",
      "Epoch 52/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5310.6206\n",
      "Epoch 52: val_loss did not improve from 5101.59326\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 5310.6206 - val_loss: 5158.8477\n",
      "Epoch 53/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5554.6758\n",
      "Epoch 53: val_loss did not improve from 5101.59326\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 5554.6758 - val_loss: 5103.0757\n",
      "Epoch 54/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5411.4424\n",
      "Epoch 54: val_loss did not improve from 5101.59326\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 5411.4424 - val_loss: 5120.5137\n",
      "Epoch 55/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5399.2188\n",
      "Epoch 55: val_loss improved from 5101.59326 to 4990.12744, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.55-t5399.22-v4990.13.hdf5\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 5399.2188 - val_loss: 4990.1274\n",
      "Epoch 56/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5280.1699\n",
      "Epoch 56: val_loss did not improve from 4990.12744\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 5280.1699 - val_loss: 4994.4941\n",
      "Epoch 57/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5216.2573\n",
      "Epoch 57: val_loss improved from 4990.12744 to 4849.72607, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.57-t5216.26-v4849.73.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 5216.2573 - val_loss: 4849.7261\n",
      "Epoch 58/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5239.2930\n",
      "Epoch 58: val_loss did not improve from 4849.72607\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 5239.2930 - val_loss: 4949.5205\n",
      "Epoch 59/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5074.3027\n",
      "Epoch 59: val_loss improved from 4849.72607 to 4766.36914, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.59-t5074.30-v4766.37.hdf5\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 5074.3027 - val_loss: 4766.3691\n",
      "Epoch 60/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5216.3125\n",
      "Epoch 60: val_loss did not improve from 4766.36914\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 5216.3125 - val_loss: 4848.6152\n",
      "Epoch 61/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5587.1509\n",
      "Epoch 61: val_loss did not improve from 4766.36914\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 5587.1509 - val_loss: 5111.1279\n",
      "Epoch 62/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5358.6968\n",
      "Epoch 62: val_loss did not improve from 4766.36914\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 5358.6968 - val_loss: 4931.1006\n",
      "Epoch 63/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5449.3481\n",
      "Epoch 63: val_loss did not improve from 4766.36914\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 5449.3481 - val_loss: 6086.1387\n",
      "Epoch 64/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5658.9121\n",
      "Epoch 64: val_loss did not improve from 4766.36914\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 5658.9121 - val_loss: 5438.8667\n",
      "Epoch 65/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5701.4448\n",
      "Epoch 65: val_loss did not improve from 4766.36914\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 5701.4448 - val_loss: 4872.3545\n",
      "Epoch 66/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5636.8926\n",
      "Epoch 66: val_loss did not improve from 4766.36914\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 5636.8926 - val_loss: 5967.6919\n",
      "Epoch 67/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5587.8325\n",
      "Epoch 67: val_loss improved from 4766.36914 to 4757.14111, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.67-t5587.83-v4757.14.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 5587.8325 - val_loss: 4757.1411\n",
      "Epoch 68/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 6447.6792\n",
      "Epoch 68: val_loss did not improve from 4757.14111\n",
      "93/93 [==============================] - 8s 80ms/step - loss: 6447.6792 - val_loss: 5834.4209\n",
      "Epoch 69/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5528.3237\n",
      "Epoch 69: val_loss did not improve from 4757.14111\n",
      "93/93 [==============================] - 7s 80ms/step - loss: 5528.3237 - val_loss: 5301.3765\n",
      "Epoch 70/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5506.4258\n",
      "Epoch 70: val_loss did not improve from 4757.14111\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 5506.4258 - val_loss: 5535.8096\n",
      "Epoch 71/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5558.4561\n",
      "Epoch 71: val_loss did not improve from 4757.14111\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 5558.4561 - val_loss: 5791.3560\n",
      "Epoch 72/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5588.0229\n",
      "Epoch 72: val_loss did not improve from 4757.14111\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 5588.0229 - val_loss: 5707.0376\n",
      "Epoch 73/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 5059.4429\n",
      "Epoch 73: val_loss did not improve from 4757.14111\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 5059.4429 - val_loss: 4823.4575\n",
      "Epoch 74/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4999.0400\n",
      "Epoch 74: val_loss improved from 4757.14111 to 4682.93701, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.74-t4999.04-v4682.94.hdf5\n",
      "93/93 [==============================] - 7s 80ms/step - loss: 4999.0400 - val_loss: 4682.9370\n",
      "Epoch 75/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4915.4717\n",
      "Epoch 75: val_loss improved from 4682.93701 to 4564.66455, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.75-t4915.47-v4564.66.hdf5\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 4915.4717 - val_loss: 4564.6646\n",
      "Epoch 76/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4779.3711\n",
      "Epoch 76: val_loss did not improve from 4564.66455\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 4779.3711 - val_loss: 4587.1709\n",
      "Epoch 77/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4806.6860\n",
      "Epoch 77: val_loss improved from 4564.66455 to 4561.48730, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.77-t4806.69-v4561.49.hdf5\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 4806.6860 - val_loss: 4561.4873\n",
      "Epoch 78/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4585.7339\n",
      "Epoch 78: val_loss improved from 4561.48730 to 4475.78223, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.78-t4585.73-v4475.78.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 4585.7339 - val_loss: 4475.7822\n",
      "Epoch 79/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4505.3882\n",
      "Epoch 79: val_loss improved from 4475.78223 to 4370.76758, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.79-t4505.39-v4370.77.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 4505.3882 - val_loss: 4370.7676\n",
      "Epoch 80/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4641.3188\n",
      "Epoch 80: val_loss did not improve from 4370.76758\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 4641.3188 - val_loss: 4881.3374\n",
      "Epoch 81/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4868.1191\n",
      "Epoch 81: val_loss did not improve from 4370.76758\n",
      "93/93 [==============================] - 7s 80ms/step - loss: 4868.1191 - val_loss: 4547.6973\n",
      "Epoch 82/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4843.9033\n",
      "Epoch 82: val_loss did not improve from 4370.76758\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 4843.9033 - val_loss: 4725.4922\n",
      "Epoch 83/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4869.2119\n",
      "Epoch 83: val_loss did not improve from 4370.76758\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 4869.2119 - val_loss: 4845.7554\n",
      "Epoch 84/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4754.0371\n",
      "Epoch 84: val_loss did not improve from 4370.76758\n",
      "93/93 [==============================] - 7s 80ms/step - loss: 4754.0371 - val_loss: 4442.1997\n",
      "Epoch 85/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4668.6978\n",
      "Epoch 85: val_loss did not improve from 4370.76758\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 4668.6978 - val_loss: 4418.2246\n",
      "Epoch 86/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4514.4482\n",
      "Epoch 86: val_loss improved from 4370.76758 to 4194.73535, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.86-t4514.45-v4194.74.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 4514.4482 - val_loss: 4194.7354\n",
      "Epoch 87/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4405.2305\n",
      "Epoch 87: val_loss did not improve from 4194.73535\n",
      "93/93 [==============================] - 8s 80ms/step - loss: 4405.2305 - val_loss: 4201.9829\n",
      "Epoch 88/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4486.2090\n",
      "Epoch 88: val_loss did not improve from 4194.73535\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 4486.2090 - val_loss: 4318.6938\n",
      "Epoch 89/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4475.6782\n",
      "Epoch 89: val_loss did not improve from 4194.73535\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 4475.6782 - val_loss: 4329.5176\n",
      "Epoch 90/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4406.8867\n",
      "Epoch 90: val_loss improved from 4194.73535 to 4135.97510, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.90-t4406.89-v4135.98.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 4406.8867 - val_loss: 4135.9751\n",
      "Epoch 91/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4465.6309\n",
      "Epoch 91: val_loss improved from 4135.97510 to 4000.79565, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.91-t4465.63-v4000.80.hdf5\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 4465.6309 - val_loss: 4000.7957\n",
      "Epoch 92/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4265.4028\n",
      "Epoch 92: val_loss did not improve from 4000.79565\n",
      "93/93 [==============================] - 8s 82ms/step - loss: 4265.4028 - val_loss: 4106.8018\n",
      "Epoch 93/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4425.5391\n",
      "Epoch 93: val_loss did not improve from 4000.79565\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 4425.5391 - val_loss: 4958.4609\n",
      "Epoch 94/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4393.4243\n",
      "Epoch 94: val_loss did not improve from 4000.79565\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 4393.4243 - val_loss: 4569.6187\n",
      "Epoch 95/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4545.0620\n",
      "Epoch 95: val_loss did not improve from 4000.79565\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 4545.0620 - val_loss: 4722.7993\n",
      "Epoch 96/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4540.7354\n",
      "Epoch 96: val_loss did not improve from 4000.79565\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 4540.7354 - val_loss: 4531.0762\n",
      "Epoch 97/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4466.5151\n",
      "Epoch 97: val_loss did not improve from 4000.79565\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 4466.5151 - val_loss: 4161.7080\n",
      "Epoch 98/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4281.5029\n",
      "Epoch 98: val_loss did not improve from 4000.79565\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 4281.5029 - val_loss: 4290.4316\n",
      "Epoch 99/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4208.9307\n",
      "Epoch 99: val_loss did not improve from 4000.79565\n",
      "93/93 [==============================] - 7s 80ms/step - loss: 4208.9307 - val_loss: 4094.5776\n",
      "Epoch 100/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4062.1909\n",
      "Epoch 100: val_loss improved from 4000.79565 to 3657.89722, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.100-t4062.19-v3657.90.hdf5\n",
      "93/93 [==============================] - 8s 82ms/step - loss: 4062.1909 - val_loss: 3657.8972\n",
      "Epoch 101/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 3750.4597\n",
      "Epoch 101: val_loss improved from 3657.89722 to 3470.27393, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.101-t3750.46-v3470.27.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 3750.4597 - val_loss: 3470.2739\n",
      "Epoch 102/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 3755.5149\n",
      "Epoch 102: val_loss did not improve from 3470.27393\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 3755.5149 - val_loss: 4963.5674\n",
      "Epoch 103/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4019.5090\n",
      "Epoch 103: val_loss did not improve from 3470.27393\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 4019.5090 - val_loss: 3561.4470\n",
      "Epoch 104/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4043.6465\n",
      "Epoch 104: val_loss did not improve from 3470.27393\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 4043.6465 - val_loss: 3670.4668\n",
      "Epoch 105/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 3428.5708\n",
      "Epoch 105: val_loss improved from 3470.27393 to 2985.70410, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.105-t3428.57-v2985.70.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 3428.5708 - val_loss: 2985.7041\n",
      "Epoch 106/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4204.1475\n",
      "Epoch 106: val_loss did not improve from 2985.70410\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 4204.1475 - val_loss: 5040.3823\n",
      "Epoch 107/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 3752.1035\n",
      "Epoch 107: val_loss did not improve from 2985.70410\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 3752.1035 - val_loss: 3013.8032\n",
      "Epoch 108/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 3324.9976\n",
      "Epoch 108: val_loss did not improve from 2985.70410\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 3324.9976 - val_loss: 3549.5024\n",
      "Epoch 109/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 2907.6848\n",
      "Epoch 109: val_loss improved from 2985.70410 to 2460.49609, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.109-t2907.68-v2460.50.hdf5\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 2907.6848 - val_loss: 2460.4961\n",
      "Epoch 110/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 2570.1067\n",
      "Epoch 110: val_loss did not improve from 2460.49609\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 2570.1067 - val_loss: 2620.7593\n",
      "Epoch 111/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 2664.6824\n",
      "Epoch 111: val_loss improved from 2460.49609 to 2234.37085, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.111-t2664.68-v2234.37.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 2664.6824 - val_loss: 2234.3708\n",
      "Epoch 112/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 2525.5808\n",
      "Epoch 112: val_loss did not improve from 2234.37085\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 2525.5808 - val_loss: 2355.2627\n",
      "Epoch 113/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 2697.2336\n",
      "Epoch 113: val_loss did not improve from 2234.37085\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 2697.2336 - val_loss: 2588.0042\n",
      "Epoch 114/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 2467.4900\n",
      "Epoch 114: val_loss did not improve from 2234.37085\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 2467.4900 - val_loss: 2456.4163\n",
      "Epoch 115/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 2330.2495\n",
      "Epoch 115: val_loss improved from 2234.37085 to 2105.90112, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.115-t2330.25-v2105.90.hdf5\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 2330.2495 - val_loss: 2105.9011\n",
      "Epoch 116/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 2069.9600\n",
      "Epoch 116: val_loss improved from 2105.90112 to 1685.65186, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.116-t2069.96-v1685.65.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 2069.9600 - val_loss: 1685.6519\n",
      "Epoch 117/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1881.0668\n",
      "Epoch 117: val_loss improved from 1685.65186 to 1640.02783, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.117-t1881.07-v1640.03.hdf5\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 1881.0668 - val_loss: 1640.0278\n",
      "Epoch 118/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1708.2992\n",
      "Epoch 118: val_loss improved from 1640.02783 to 1504.92493, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.118-t1708.30-v1504.92.hdf5\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 1708.2992 - val_loss: 1504.9249\n",
      "Epoch 119/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1743.4038\n",
      "Epoch 119: val_loss did not improve from 1504.92493\n",
      "93/93 [==============================] - 7s 80ms/step - loss: 1743.4038 - val_loss: 2056.1641\n",
      "Epoch 120/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1647.5865\n",
      "Epoch 120: val_loss improved from 1504.92493 to 1342.64038, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.120-t1647.59-v1342.64.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 1647.5865 - val_loss: 1342.6404\n",
      "Epoch 121/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1820.9248\n",
      "Epoch 121: val_loss did not improve from 1342.64038\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 1820.9248 - val_loss: 1680.8546\n",
      "Epoch 122/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1607.5835\n",
      "Epoch 122: val_loss did not improve from 1342.64038\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 1607.5835 - val_loss: 1596.9888\n",
      "Epoch 123/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1886.9087\n",
      "Epoch 123: val_loss did not improve from 1342.64038\n",
      "93/93 [==============================] - 7s 80ms/step - loss: 1886.9087 - val_loss: 1935.2585\n",
      "Epoch 124/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1901.1945\n",
      "Epoch 124: val_loss did not improve from 1342.64038\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 1901.1945 - val_loss: 1739.0693\n",
      "Epoch 125/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1567.5330\n",
      "Epoch 125: val_loss did not improve from 1342.64038\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 1567.5330 - val_loss: 2020.7091\n",
      "Epoch 126/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1695.0006\n",
      "Epoch 126: val_loss did not improve from 1342.64038\n",
      "93/93 [==============================] - 7s 74ms/step - loss: 1695.0006 - val_loss: 1676.7032\n",
      "Epoch 127/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1593.2633\n",
      "Epoch 127: val_loss improved from 1342.64038 to 1103.14868, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.127-t1593.26-v1103.15.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 1593.2633 - val_loss: 1103.1487\n",
      "Epoch 128/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1407.0502\n",
      "Epoch 128: val_loss improved from 1103.14868 to 1037.41345, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.128-t1407.05-v1037.41.hdf5\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 1407.0502 - val_loss: 1037.4135\n",
      "Epoch 129/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1336.0524\n",
      "Epoch 129: val_loss did not improve from 1037.41345\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 1336.0524 - val_loss: 1220.5135\n",
      "Epoch 130/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1576.5203\n",
      "Epoch 130: val_loss did not improve from 1037.41345\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 1576.5203 - val_loss: 1614.3500\n",
      "Epoch 131/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1350.2351\n",
      "Epoch 131: val_loss did not improve from 1037.41345\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 1350.2351 - val_loss: 1236.5977\n",
      "Epoch 132/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1425.3948\n",
      "Epoch 132: val_loss did not improve from 1037.41345\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 1425.3948 - val_loss: 1222.7024\n",
      "Epoch 133/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1204.1992\n",
      "Epoch 133: val_loss did not improve from 1037.41345\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 1204.1992 - val_loss: 1048.3838\n",
      "Epoch 134/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1020.9948\n",
      "Epoch 134: val_loss did not improve from 1037.41345\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 1020.9948 - val_loss: 1079.8728\n",
      "Epoch 135/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 943.1877\n",
      "Epoch 135: val_loss improved from 1037.41345 to 671.49414, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.135-t943.19-v671.49.hdf5\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 943.1877 - val_loss: 671.4941\n",
      "Epoch 136/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1223.6432\n",
      "Epoch 136: val_loss did not improve from 671.49414\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 1223.6432 - val_loss: 1052.2161\n",
      "Epoch 137/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 929.4075\n",
      "Epoch 137: val_loss did not improve from 671.49414\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 929.4075 - val_loss: 830.4183\n",
      "Epoch 138/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1060.4741\n",
      "Epoch 138: val_loss did not improve from 671.49414\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 1060.4741 - val_loss: 792.2937\n",
      "Epoch 139/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 908.5340\n",
      "Epoch 139: val_loss did not improve from 671.49414\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 908.5340 - val_loss: 754.5345\n",
      "Epoch 140/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 957.1710\n",
      "Epoch 140: val_loss did not improve from 671.49414\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 957.1710 - val_loss: 911.5289\n",
      "Epoch 141/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 926.7886\n",
      "Epoch 141: val_loss improved from 671.49414 to 587.81317, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.141-t926.79-v587.81.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 926.7886 - val_loss: 587.8132\n",
      "Epoch 142/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 865.9149\n",
      "Epoch 142: val_loss did not improve from 587.81317\n",
      "93/93 [==============================] - 7s 75ms/step - loss: 865.9149 - val_loss: 648.9316\n",
      "Epoch 143/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 952.6785\n",
      "Epoch 143: val_loss did not improve from 587.81317\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 952.6785 - val_loss: 656.9142\n",
      "Epoch 144/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1011.3816\n",
      "Epoch 144: val_loss did not improve from 587.81317\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 1011.3816 - val_loss: 962.6408\n",
      "Epoch 145/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 745.4791\n",
      "Epoch 145: val_loss did not improve from 587.81317\n",
      "93/93 [==============================] - 7s 75ms/step - loss: 745.4791 - val_loss: 1476.5538\n",
      "Epoch 146/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 777.7453\n",
      "Epoch 146: val_loss did not improve from 587.81317\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 777.7453 - val_loss: 1178.4719\n",
      "Epoch 147/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 710.5741\n",
      "Epoch 147: val_loss improved from 587.81317 to 447.70602, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.147-t710.57-v447.71.hdf5\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 710.5741 - val_loss: 447.7060\n",
      "Epoch 148/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 740.9011\n",
      "Epoch 148: val_loss did not improve from 447.70602\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 740.9011 - val_loss: 480.2979\n",
      "Epoch 149/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 528.4289\n",
      "Epoch 149: val_loss improved from 447.70602 to 265.69287, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.149-t528.43-v265.69.hdf5\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 528.4289 - val_loss: 265.6929\n",
      "Epoch 150/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1055.9220\n",
      "Epoch 150: val_loss did not improve from 265.69287\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 1055.9220 - val_loss: 314.0703\n",
      "Epoch 151/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 422.3012\n",
      "Epoch 151: val_loss did not improve from 265.69287\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 422.3012 - val_loss: 435.0983\n",
      "Epoch 152/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 601.1748\n",
      "Epoch 152: val_loss did not improve from 265.69287\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 601.1748 - val_loss: 318.3094\n",
      "Epoch 153/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 1253.1068\n",
      "Epoch 153: val_loss did not improve from 265.69287\n",
      "93/93 [==============================] - 7s 74ms/step - loss: 1253.1068 - val_loss: 327.5380\n",
      "Epoch 154/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 513.2083\n",
      "Epoch 154: val_loss improved from 265.69287 to 201.66658, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.154-t513.21-v201.67.hdf5\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 513.2083 - val_loss: 201.6666\n",
      "Epoch 155/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 371.1211\n",
      "Epoch 155: val_loss did not improve from 201.66658\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 371.1211 - val_loss: 498.0070\n",
      "Epoch 156/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 445.6879\n",
      "Epoch 156: val_loss did not improve from 201.66658\n",
      "93/93 [==============================] - 8s 82ms/step - loss: 445.6879 - val_loss: 454.7004\n",
      "Epoch 157/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 495.4374\n",
      "Epoch 157: val_loss did not improve from 201.66658\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 495.4374 - val_loss: 885.9141\n",
      "Epoch 158/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 535.7552\n",
      "Epoch 158: val_loss did not improve from 201.66658\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 535.7552 - val_loss: 337.3903\n",
      "Epoch 159/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 443.5871\n",
      "Epoch 159: val_loss did not improve from 201.66658\n",
      "93/93 [==============================] - 7s 75ms/step - loss: 443.5871 - val_loss: 898.1270\n",
      "Epoch 160/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 893.7819\n",
      "Epoch 160: val_loss did not improve from 201.66658\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 893.7819 - val_loss: 2689.5166\n",
      "Epoch 161/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 895.5938\n",
      "Epoch 161: val_loss improved from 201.66658 to 106.03368, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.161-t895.59-v106.03.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 895.5938 - val_loss: 106.0337\n",
      "Epoch 162/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 147.8155\n",
      "Epoch 162: val_loss did not improve from 106.03368\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 147.8155 - val_loss: 172.9376\n",
      "Epoch 163/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 141.0295\n",
      "Epoch 163: val_loss improved from 106.03368 to -61.95603, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.163-t141.03-v-61.96.hdf5\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 141.0295 - val_loss: -61.9560\n",
      "Epoch 164/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 91.4167\n",
      "Epoch 164: val_loss did not improve from -61.95603\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 91.4167 - val_loss: -37.6108\n",
      "Epoch 165/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 376.3762\n",
      "Epoch 165: val_loss improved from -61.95603 to -183.05551, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.165-t376.38-v-183.06.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 376.3762 - val_loss: -183.0555\n",
      "Epoch 166/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 166.4696\n",
      "Epoch 166: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 8s 89ms/step - loss: 166.4696 - val_loss: 344.8747\n",
      "Epoch 167/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 666.3220\n",
      "Epoch 167: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 666.3220 - val_loss: 142.8886\n",
      "Epoch 168/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 241.2785\n",
      "Epoch 168: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 241.2785 - val_loss: 733.3547\n",
      "Epoch 169/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 274.1284\n",
      "Epoch 169: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 7s 75ms/step - loss: 274.1284 - val_loss: 280.5242\n",
      "Epoch 170/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 199.0796\n",
      "Epoch 170: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 199.0796 - val_loss: -21.9027\n",
      "Epoch 171/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 181.4445\n",
      "Epoch 171: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 181.4445 - val_loss: 317.5965\n",
      "Epoch 172/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 75.7580\n",
      "Epoch 172: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 75.7580 - val_loss: 215.9070\n",
      "Epoch 173/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 184.5343\n",
      "Epoch 173: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 7s 74ms/step - loss: 184.5343 - val_loss: 310.1817\n",
      "Epoch 174/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 228.8533\n",
      "Epoch 174: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 228.8533 - val_loss: 317.1519\n",
      "Epoch 175/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 445.4311\n",
      "Epoch 175: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 445.4311 - val_loss: 338.6458\n",
      "Epoch 176/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 621.2040\n",
      "Epoch 176: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 621.2040 - val_loss: 425.2388\n",
      "Epoch 177/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 455.7233\n",
      "Epoch 177: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 455.7233 - val_loss: 458.2244\n",
      "Epoch 178/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 406.9095\n",
      "Epoch 178: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 406.9095 - val_loss: -93.8333\n",
      "Epoch 179/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 307.5186\n",
      "Epoch 179: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 307.5186 - val_loss: 406.7644\n",
      "Epoch 180/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 80.3322\n",
      "Epoch 180: val_loss did not improve from -183.05551\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 80.3322 - val_loss: 701.9951\n",
      "Epoch 181/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -45.9477\n",
      "Epoch 181: val_loss improved from -183.05551 to -367.08890, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.181-t-45.95-v-367.09.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -45.9477 - val_loss: -367.0889\n",
      "Epoch 182/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -158.7931\n",
      "Epoch 182: val_loss did not improve from -367.08890\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -158.7931 - val_loss: 103.6492\n",
      "Epoch 183/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -76.6972\n",
      "Epoch 183: val_loss did not improve from -367.08890\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -76.6972 - val_loss: -190.1318\n",
      "Epoch 184/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -129.2419\n",
      "Epoch 184: val_loss did not improve from -367.08890\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -129.2419 - val_loss: 149.7732\n",
      "Epoch 185/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -125.6390\n",
      "Epoch 185: val_loss did not improve from -367.08890\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -125.6390 - val_loss: -173.8660\n",
      "Epoch 186/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -165.6635\n",
      "Epoch 186: val_loss did not improve from -367.08890\n",
      "93/93 [==============================] - 7s 77ms/step - loss: -165.6635 - val_loss: 134.6884\n",
      "Epoch 187/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -149.6961\n",
      "Epoch 187: val_loss improved from -367.08890 to -431.18182, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.187-t-149.70-v-431.18.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -149.6961 - val_loss: -431.1818\n",
      "Epoch 188/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 389.5741\n",
      "Epoch 188: val_loss did not improve from -431.18182\n",
      "93/93 [==============================] - 8s 80ms/step - loss: 389.5741 - val_loss: 2263.1267\n",
      "Epoch 189/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 544.2330\n",
      "Epoch 189: val_loss improved from -431.18182 to -431.60822, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.189-t544.23-v-431.61.hdf5\n",
      "93/93 [==============================] - 8s 80ms/step - loss: 544.2330 - val_loss: -431.6082\n",
      "Epoch 190/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 4.3631\n",
      "Epoch 190: val_loss improved from -431.60822 to -433.62476, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.190-t4.36-v-433.62.hdf5\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 4.3631 - val_loss: -433.6248\n",
      "Epoch 191/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -23.7213\n",
      "Epoch 191: val_loss did not improve from -433.62476\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -23.7213 - val_loss: -215.0719\n",
      "Epoch 192/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -83.1762\n",
      "Epoch 192: val_loss did not improve from -433.62476\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -83.1762 - val_loss: -349.2789\n",
      "Epoch 193/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -207.4687\n",
      "Epoch 193: val_loss improved from -433.62476 to -455.19513, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.193-t-207.47-v-455.20.hdf5\n",
      "93/93 [==============================] - 7s 77ms/step - loss: -207.4687 - val_loss: -455.1951\n",
      "Epoch 194/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -165.9431\n",
      "Epoch 194: val_loss did not improve from -455.19513\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -165.9431 - val_loss: 59.4017\n",
      "Epoch 195/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -76.8149\n",
      "Epoch 195: val_loss did not improve from -455.19513\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -76.8149 - val_loss: -241.2496\n",
      "Epoch 196/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -149.3100\n",
      "Epoch 196: val_loss did not improve from -455.19513\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -149.3100 - val_loss: -301.4348\n",
      "Epoch 197/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -239.0156\n",
      "Epoch 197: val_loss did not improve from -455.19513\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -239.0156 - val_loss: -221.6125\n",
      "Epoch 198/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -248.9074\n",
      "Epoch 198: val_loss did not improve from -455.19513\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -248.9074 - val_loss: -200.5931\n",
      "Epoch 199/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -98.8505\n",
      "Epoch 199: val_loss did not improve from -455.19513\n",
      "93/93 [==============================] - 8s 80ms/step - loss: -98.8505 - val_loss: -212.4440\n",
      "Epoch 200/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -191.2322\n",
      "Epoch 200: val_loss did not improve from -455.19513\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -191.2322 - val_loss: 117.6556\n",
      "Epoch 201/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -244.6911\n",
      "Epoch 201: val_loss improved from -455.19513 to -503.67133, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.201-t-244.69-v-503.67.hdf5\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -244.6911 - val_loss: -503.6713\n",
      "Epoch 202/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -261.9351\n",
      "Epoch 202: val_loss did not improve from -503.67133\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -261.9351 - val_loss: -77.8282\n",
      "Epoch 203/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -267.8928\n",
      "Epoch 203: val_loss did not improve from -503.67133\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -267.8928 - val_loss: -205.2889\n",
      "Epoch 204/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -336.1083\n",
      "Epoch 204: val_loss did not improve from -503.67133\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -336.1083 - val_loss: -361.9138\n",
      "Epoch 205/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -355.7982\n",
      "Epoch 205: val_loss did not improve from -503.67133\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -355.7982 - val_loss: -264.5643\n",
      "Epoch 206/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -410.0988\n",
      "Epoch 206: val_loss improved from -503.67133 to -558.67615, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.206-t-410.10-v-558.68.hdf5\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -410.0988 - val_loss: -558.6761\n",
      "Epoch 207/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -332.5185\n",
      "Epoch 207: val_loss did not improve from -558.67615\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -332.5185 - val_loss: -176.8082\n",
      "Epoch 208/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -473.9036\n",
      "Epoch 208: val_loss did not improve from -558.67615\n",
      "93/93 [==============================] - 7s 75ms/step - loss: -473.9036 - val_loss: -439.2220\n",
      "Epoch 209/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -331.5795\n",
      "Epoch 209: val_loss improved from -558.67615 to -718.54639, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.209-t-331.58-v-718.55.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -331.5795 - val_loss: -718.5464\n",
      "Epoch 210/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -512.0029\n",
      "Epoch 210: val_loss did not improve from -718.54639\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -512.0029 - val_loss: -301.8387\n",
      "Epoch 211/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -512.2728\n",
      "Epoch 211: val_loss did not improve from -718.54639\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -512.2728 - val_loss: -218.3622\n",
      "Epoch 212/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -465.9301\n",
      "Epoch 212: val_loss did not improve from -718.54639\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -465.9301 - val_loss: -340.2437\n",
      "Epoch 213/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -287.0066\n",
      "Epoch 213: val_loss did not improve from -718.54639\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -287.0066 - val_loss: 422.4664\n",
      "Epoch 214/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -209.5061\n",
      "Epoch 214: val_loss did not improve from -718.54639\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -209.5061 - val_loss: -624.1360\n",
      "Epoch 215/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -526.3312\n",
      "Epoch 215: val_loss did not improve from -718.54639\n",
      "93/93 [==============================] - 8s 80ms/step - loss: -526.3312 - val_loss: 225.1273\n",
      "Epoch 216/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -504.7279\n",
      "Epoch 216: val_loss did not improve from -718.54639\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -504.7279 - val_loss: -587.5862\n",
      "Epoch 217/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -452.0557\n",
      "Epoch 217: val_loss improved from -718.54639 to -720.00800, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.217-t-452.06-v-720.01.hdf5\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -452.0557 - val_loss: -720.0080\n",
      "Epoch 218/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2.9211\n",
      "Epoch 218: val_loss did not improve from -720.00800\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -2.9211 - val_loss: -259.0184\n",
      "Epoch 219/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -492.1398\n",
      "Epoch 219: val_loss improved from -720.00800 to -859.19940, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.219-t-492.14-v-859.20.hdf5\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -492.1398 - val_loss: -859.1994\n",
      "Epoch 220/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -576.9371\n",
      "Epoch 220: val_loss did not improve from -859.19940\n",
      "93/93 [==============================] - 8s 80ms/step - loss: -576.9371 - val_loss: -653.8030\n",
      "Epoch 221/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -573.1812\n",
      "Epoch 221: val_loss did not improve from -859.19940\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -573.1812 - val_loss: -788.5788\n",
      "Epoch 222/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -661.0856\n",
      "Epoch 222: val_loss improved from -859.19940 to -878.79047, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.222-t-661.09-v-878.79.hdf5\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -661.0856 - val_loss: -878.7905\n",
      "Epoch 223/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -709.2823\n",
      "Epoch 223: val_loss improved from -878.79047 to -939.76398, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.223-t-709.28-v-939.76.hdf5\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -709.2823 - val_loss: -939.7640\n",
      "Epoch 224/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -764.3690\n",
      "Epoch 224: val_loss did not improve from -939.76398\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -764.3690 - val_loss: -271.1812\n",
      "Epoch 225/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -426.5314\n",
      "Epoch 225: val_loss did not improve from -939.76398\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -426.5314 - val_loss: -617.1539\n",
      "Epoch 226/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -644.7330\n",
      "Epoch 226: val_loss did not improve from -939.76398\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -644.7330 - val_loss: -789.4084\n",
      "Epoch 227/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -411.3548\n",
      "Epoch 227: val_loss improved from -939.76398 to -945.17688, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.227-t-411.35-v-945.18.hdf5\n",
      "93/93 [==============================] - 8s 88ms/step - loss: -411.3548 - val_loss: -945.1769\n",
      "Epoch 228/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -887.7021\n",
      "Epoch 228: val_loss did not improve from -945.17688\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -887.7021 - val_loss: -555.3909\n",
      "Epoch 229/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -873.2578\n",
      "Epoch 229: val_loss did not improve from -945.17688\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -873.2578 - val_loss: -863.7530\n",
      "Epoch 230/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -938.6103\n",
      "Epoch 230: val_loss improved from -945.17688 to -1156.37964, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.230-t-938.61-v-1156.38.hdf5\n",
      "93/93 [==============================] - 8s 85ms/step - loss: -938.6103 - val_loss: -1156.3796\n",
      "Epoch 231/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -876.4980\n",
      "Epoch 231: val_loss did not improve from -1156.37964\n",
      "93/93 [==============================] - 8s 85ms/step - loss: -876.4980 - val_loss: -1085.6949\n",
      "Epoch 232/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1034.6251\n",
      "Epoch 232: val_loss did not improve from -1156.37964\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -1034.6251 - val_loss: -1074.0555\n",
      "Epoch 233/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1103.7822\n",
      "Epoch 233: val_loss did not improve from -1156.37964\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -1103.7822 - val_loss: -1150.6554\n",
      "Epoch 234/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1187.1488\n",
      "Epoch 234: val_loss improved from -1156.37964 to -1236.13684, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.234-t-1187.15-v-1236.14.hdf5\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -1187.1488 - val_loss: -1236.1368\n",
      "Epoch 235/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1088.3164\n",
      "Epoch 235: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 85ms/step - loss: -1088.3164 - val_loss: -1180.6716\n",
      "Epoch 236/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1053.9253\n",
      "Epoch 236: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1053.9253 - val_loss: -947.7191\n",
      "Epoch 237/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1132.5150\n",
      "Epoch 237: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -1132.5150 - val_loss: -1003.7296\n",
      "Epoch 238/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1155.4731\n",
      "Epoch 238: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -1155.4731 - val_loss: -1184.5714\n",
      "Epoch 239/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1076.3086\n",
      "Epoch 239: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -1076.3086 - val_loss: -795.9055\n",
      "Epoch 240/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1059.1691\n",
      "Epoch 240: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 85ms/step - loss: -1059.1691 - val_loss: -1035.6770\n",
      "Epoch 241/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1075.8309\n",
      "Epoch 241: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 86ms/step - loss: -1075.8309 - val_loss: -983.0671\n",
      "Epoch 242/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -887.3714\n",
      "Epoch 242: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -887.3714 - val_loss: -1058.5118\n",
      "Epoch 243/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1031.9211\n",
      "Epoch 243: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -1031.9211 - val_loss: -1178.2839\n",
      "Epoch 244/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1078.1509\n",
      "Epoch 244: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 86ms/step - loss: -1078.1509 - val_loss: -968.0982\n",
      "Epoch 245/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -947.4767\n",
      "Epoch 245: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -947.4767 - val_loss: -877.4219\n",
      "Epoch 246/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -935.5757\n",
      "Epoch 246: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -935.5757 - val_loss: -1234.9125\n",
      "Epoch 247/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -871.7219\n",
      "Epoch 247: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -871.7219 - val_loss: -906.2232\n",
      "Epoch 248/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -977.1312\n",
      "Epoch 248: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -977.1312 - val_loss: -1206.0148\n",
      "Epoch 249/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -965.3007\n",
      "Epoch 249: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 87ms/step - loss: -965.3007 - val_loss: -1118.6885\n",
      "Epoch 250/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -505.5928\n",
      "Epoch 250: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -505.5928 - val_loss: -216.2220\n",
      "Epoch 251/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -871.8318\n",
      "Epoch 251: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 85ms/step - loss: -871.8318 - val_loss: -344.9661\n",
      "Epoch 252/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1040.1659\n",
      "Epoch 252: val_loss did not improve from -1236.13684\n",
      "93/93 [==============================] - 8s 85ms/step - loss: -1040.1659 - val_loss: -490.0438\n",
      "Epoch 253/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -927.0557\n",
      "Epoch 253: val_loss improved from -1236.13684 to -1256.70679, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.253-t-927.06-v-1256.71.hdf5\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -927.0557 - val_loss: -1256.7068\n",
      "Epoch 254/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -835.3632\n",
      "Epoch 254: val_loss did not improve from -1256.70679\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -835.3632 - val_loss: -844.9730\n",
      "Epoch 255/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 529.5946\n",
      "Epoch 255: val_loss did not improve from -1256.70679\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 529.5946 - val_loss: 94.6189\n",
      "Epoch 256/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -673.7256\n",
      "Epoch 256: val_loss did not improve from -1256.70679\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -673.7256 - val_loss: -790.1156\n",
      "Epoch 257/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -823.1847\n",
      "Epoch 257: val_loss did not improve from -1256.70679\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -823.1847 - val_loss: -840.2968\n",
      "Epoch 258/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1082.3380\n",
      "Epoch 258: val_loss did not improve from -1256.70679\n",
      "93/93 [==============================] - 8s 86ms/step - loss: -1082.3380 - val_loss: -1183.5408\n",
      "Epoch 259/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -999.0214 \n",
      "Epoch 259: val_loss did not improve from -1256.70679\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -999.0214 - val_loss: -232.6741\n",
      "Epoch 260/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1020.8417\n",
      "Epoch 260: val_loss did not improve from -1256.70679\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -1020.8417 - val_loss: -796.0020\n",
      "Epoch 261/500\n",
      "92/93 [============================>.] - ETA: 0s - loss: -1137.5565\n",
      "Epoch 261: val_loss did not improve from -1256.70679\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -1134.2419 - val_loss: -1176.1187\n",
      "Epoch 262/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1097.9907\n",
      "Epoch 262: val_loss did not improve from -1256.70679\n",
      "93/93 [==============================] - 8s 88ms/step - loss: -1097.9907 - val_loss: -695.8074\n",
      "Epoch 263/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1055.7476\n",
      "Epoch 263: val_loss did not improve from -1256.70679\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -1055.7476 - val_loss: -1134.7380\n",
      "Epoch 264/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1222.1930\n",
      "Epoch 264: val_loss did not improve from -1256.70679\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -1222.1930 - val_loss: -1136.6530\n",
      "Epoch 265/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1145.7689\n",
      "Epoch 265: val_loss improved from -1256.70679 to -1396.52979, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.265-t-1145.77-v-1396.53.hdf5\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -1145.7689 - val_loss: -1396.5298\n",
      "Epoch 266/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -531.3824\n",
      "Epoch 266: val_loss did not improve from -1396.52979\n",
      "93/93 [==============================] - 8s 85ms/step - loss: -531.3824 - val_loss: 1317.6493\n",
      "Epoch 267/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -164.2627\n",
      "Epoch 267: val_loss did not improve from -1396.52979\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -164.2627 - val_loss: -1066.6715\n",
      "Epoch 268/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1191.2006\n",
      "Epoch 268: val_loss did not improve from -1396.52979\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -1191.2006 - val_loss: -857.3343\n",
      "Epoch 269/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1307.2697\n",
      "Epoch 269: val_loss did not improve from -1396.52979\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -1307.2697 - val_loss: -1255.6500\n",
      "Epoch 270/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1332.0903\n",
      "Epoch 270: val_loss did not improve from -1396.52979\n",
      "93/93 [==============================] - 8s 86ms/step - loss: -1332.0903 - val_loss: -1159.9858\n",
      "Epoch 271/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1119.7693\n",
      "Epoch 271: val_loss did not improve from -1396.52979\n",
      "93/93 [==============================] - 8s 86ms/step - loss: -1119.7693 - val_loss: -1178.4183\n",
      "Epoch 272/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1075.1534\n",
      "Epoch 272: val_loss did not improve from -1396.52979\n",
      "93/93 [==============================] - 8s 86ms/step - loss: -1075.1534 - val_loss: -1224.9812\n",
      "Epoch 273/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1114.7263\n",
      "Epoch 273: val_loss did not improve from -1396.52979\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -1114.7263 - val_loss: -1346.5604\n",
      "Epoch 274/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -890.1733\n",
      "Epoch 274: val_loss did not improve from -1396.52979\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -890.1733 - val_loss: -1343.8284\n",
      "Epoch 275/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -938.7081\n",
      "Epoch 275: val_loss did not improve from -1396.52979\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -938.7081 - val_loss: -970.6785\n",
      "Epoch 276/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -994.0582\n",
      "Epoch 276: val_loss did not improve from -1396.52979\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -994.0582 - val_loss: -1131.0873\n",
      "Epoch 277/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -126.5160\n",
      "Epoch 277: val_loss did not improve from -1396.52979\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -126.5160 - val_loss: -566.3174\n",
      "Epoch 278/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1103.3242\n",
      "Epoch 278: val_loss improved from -1396.52979 to -1503.62488, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.278-t-1103.32-v-1503.62.hdf5\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -1103.3242 - val_loss: -1503.6249\n",
      "Epoch 279/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1160.0693\n",
      "Epoch 279: val_loss did not improve from -1503.62488\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -1160.0693 - val_loss: -1449.4581\n",
      "Epoch 280/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1012.0892\n",
      "Epoch 280: val_loss did not improve from -1503.62488\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -1012.0892 - val_loss: -937.8176\n",
      "Epoch 281/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1137.2214\n",
      "Epoch 281: val_loss improved from -1503.62488 to -1528.67151, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.281-t-1137.22-v-1528.67.hdf5\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -1137.2214 - val_loss: -1528.6715\n",
      "Epoch 282/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -990.1550\n",
      "Epoch 282: val_loss did not improve from -1528.67151\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -990.1550 - val_loss: 965.0903\n",
      "Epoch 283/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1007.5555\n",
      "Epoch 283: val_loss did not improve from -1528.67151\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -1007.5555 - val_loss: -1075.2136\n",
      "Epoch 284/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -689.3647\n",
      "Epoch 284: val_loss did not improve from -1528.67151\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -689.3647 - val_loss: -1372.2664\n",
      "Epoch 285/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -925.8129\n",
      "Epoch 285: val_loss did not improve from -1528.67151\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -925.8129 - val_loss: -700.6629\n",
      "Epoch 286/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1055.3558\n",
      "Epoch 286: val_loss did not improve from -1528.67151\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -1055.3558 - val_loss: -1259.0361\n",
      "Epoch 287/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -85.8980\n",
      "Epoch 287: val_loss did not improve from -1528.67151\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -85.8980 - val_loss: -1052.1442\n",
      "Epoch 288/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1177.5331\n",
      "Epoch 288: val_loss did not improve from -1528.67151\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1177.5331 - val_loss: -814.1525\n",
      "Epoch 289/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1298.2229\n",
      "Epoch 289: val_loss did not improve from -1528.67151\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -1298.2229 - val_loss: -1294.2959\n",
      "Epoch 290/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1317.9436\n",
      "Epoch 290: val_loss did not improve from -1528.67151\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -1317.9436 - val_loss: -1449.6992\n",
      "Epoch 291/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -936.6151\n",
      "Epoch 291: val_loss did not improve from -1528.67151\n",
      "93/93 [==============================] - 8s 80ms/step - loss: -936.6151 - val_loss: -1480.4625\n",
      "Epoch 292/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1472.2534\n",
      "Epoch 292: val_loss improved from -1528.67151 to -1714.78296, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.292-t-1472.25-v-1714.78.hdf5\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -1472.2534 - val_loss: -1714.7830\n",
      "Epoch 293/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1504.2335\n",
      "Epoch 293: val_loss did not improve from -1714.78296\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -1504.2335 - val_loss: -1338.7319\n",
      "Epoch 294/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1578.2443\n",
      "Epoch 294: val_loss did not improve from -1714.78296\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1578.2443 - val_loss: -1674.4384\n",
      "Epoch 295/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1562.2936\n",
      "Epoch 295: val_loss improved from -1714.78296 to -1723.18774, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.295-t-1562.29-v-1723.19.hdf5\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -1562.2936 - val_loss: -1723.1877\n",
      "Epoch 296/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1555.8146\n",
      "Epoch 296: val_loss did not improve from -1723.18774\n",
      "93/93 [==============================] - 8s 80ms/step - loss: -1555.8146 - val_loss: -1597.4368\n",
      "Epoch 297/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1488.3810\n",
      "Epoch 297: val_loss did not improve from -1723.18774\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -1488.3810 - val_loss: -1354.7832\n",
      "Epoch 298/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1579.6610\n",
      "Epoch 298: val_loss did not improve from -1723.18774\n",
      "93/93 [==============================] - 7s 77ms/step - loss: -1579.6610 - val_loss: -926.1860\n",
      "Epoch 299/500\n",
      "92/93 [============================>.] - ETA: 0s - loss: -1614.8455\n",
      "Epoch 299: val_loss did not improve from -1723.18774\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -1609.5558 - val_loss: -1154.4716\n",
      "Epoch 300/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1589.1290\n",
      "Epoch 300: val_loss did not improve from -1723.18774\n",
      "93/93 [==============================] - 8s 88ms/step - loss: -1589.1290 - val_loss: -1489.2581\n",
      "Epoch 301/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1689.7548\n",
      "Epoch 301: val_loss did not improve from -1723.18774\n",
      "93/93 [==============================] - 8s 85ms/step - loss: -1689.7548 - val_loss: -1593.9241\n",
      "Epoch 302/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1661.7872\n",
      "Epoch 302: val_loss did not improve from -1723.18774\n",
      "93/93 [==============================] - 8s 85ms/step - loss: -1661.7872 - val_loss: -1578.6442\n",
      "Epoch 303/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1678.2535\n",
      "Epoch 303: val_loss did not improve from -1723.18774\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -1678.2535 - val_loss: -1249.8540\n",
      "Epoch 304/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1636.2887\n",
      "Epoch 304: val_loss did not improve from -1723.18774\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -1636.2887 - val_loss: -1683.8114\n",
      "Epoch 305/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1695.9454\n",
      "Epoch 305: val_loss did not improve from -1723.18774\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -1695.9454 - val_loss: -1160.8389\n",
      "Epoch 306/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1772.5189\n",
      "Epoch 306: val_loss did not improve from -1723.18774\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1772.5189 - val_loss: -1184.9246\n",
      "Epoch 307/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1719.1511\n",
      "Epoch 307: val_loss did not improve from -1723.18774\n",
      "93/93 [==============================] - 8s 80ms/step - loss: -1719.1511 - val_loss: -1710.5858\n",
      "Epoch 308/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1697.6298\n",
      "Epoch 308: val_loss did not improve from -1723.18774\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1697.6298 - val_loss: -1639.5917\n",
      "Epoch 309/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1664.8206\n",
      "Epoch 309: val_loss did not improve from -1723.18774\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1664.8206 - val_loss: -1106.1760\n",
      "Epoch 310/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1618.2137\n",
      "Epoch 310: val_loss improved from -1723.18774 to -1930.68445, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.310-t-1618.21-v-1930.68.hdf5\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -1618.2137 - val_loss: -1930.6844\n",
      "Epoch 311/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1533.1804\n",
      "Epoch 311: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -1533.1804 - val_loss: 308.6996\n",
      "Epoch 312/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1539.4375\n",
      "Epoch 312: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -1539.4375 - val_loss: -1577.1810\n",
      "Epoch 313/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1716.6061\n",
      "Epoch 313: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -1716.6061 - val_loss: -1576.8348\n",
      "Epoch 314/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1818.5428\n",
      "Epoch 314: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -1818.5428 - val_loss: -1760.5944\n",
      "Epoch 315/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1592.4098\n",
      "Epoch 315: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -1592.4098 - val_loss: -1736.8606\n",
      "Epoch 316/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1844.4100\n",
      "Epoch 316: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 77ms/step - loss: -1844.4100 - val_loss: -1292.1644\n",
      "Epoch 317/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1597.0570\n",
      "Epoch 317: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 8s 79ms/step - loss: -1597.0570 - val_loss: -1880.2703\n",
      "Epoch 318/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1726.8087\n",
      "Epoch 318: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -1726.8087 - val_loss: -1874.3741\n",
      "Epoch 319/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1779.6564\n",
      "Epoch 319: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 77ms/step - loss: -1779.6564 - val_loss: -1649.8805\n",
      "Epoch 320/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1783.8949\n",
      "Epoch 320: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -1783.8949 - val_loss: -1798.3577\n",
      "Epoch 321/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 10.7066\n",
      "Epoch 321: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 8s 78ms/step - loss: 10.7066 - val_loss: -1920.0626\n",
      "Epoch 322/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2024.7017\n",
      "Epoch 322: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 76ms/step - loss: -2024.7017 - val_loss: -1661.6827\n",
      "Epoch 323/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1919.0626\n",
      "Epoch 323: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -1919.0626 - val_loss: -1759.0886\n",
      "Epoch 324/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1882.6393\n",
      "Epoch 324: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1882.6393 - val_loss: -1669.2748\n",
      "Epoch 325/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1949.0643\n",
      "Epoch 325: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -1949.0643 - val_loss: -1877.7303\n",
      "Epoch 326/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1980.5634\n",
      "Epoch 326: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -1980.5634 - val_loss: -1629.1960\n",
      "Epoch 327/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1926.4467\n",
      "Epoch 327: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -1926.4467 - val_loss: -1915.0300\n",
      "Epoch 328/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1825.2728\n",
      "Epoch 328: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1825.2728 - val_loss: -1696.7898\n",
      "Epoch 329/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2013.0763\n",
      "Epoch 329: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -2013.0763 - val_loss: -1549.3689\n",
      "Epoch 330/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1894.4076\n",
      "Epoch 330: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -1894.4076 - val_loss: -1612.0953\n",
      "Epoch 331/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1922.8899\n",
      "Epoch 331: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 77ms/step - loss: -1922.8899 - val_loss: -1774.1708\n",
      "Epoch 332/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1972.0696\n",
      "Epoch 332: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1972.0696 - val_loss: -1453.8263\n",
      "Epoch 333/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -724.7360\n",
      "Epoch 333: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -724.7360 - val_loss: 2193.2441\n",
      "Epoch 334/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -71.8000\n",
      "Epoch 334: val_loss did not improve from -1930.68445\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -71.8000 - val_loss: -1399.4904\n",
      "Epoch 335/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1706.3348\n",
      "Epoch 335: val_loss improved from -1930.68445 to -1930.75781, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.335-t-1706.33-v-1930.76.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1706.3348 - val_loss: -1930.7578\n",
      "Epoch 336/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2078.5828\n",
      "Epoch 336: val_loss did not improve from -1930.75781\n",
      "93/93 [==============================] - 8s 80ms/step - loss: -2078.5828 - val_loss: -1903.6534\n",
      "Epoch 337/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2209.0557\n",
      "Epoch 337: val_loss did not improve from -1930.75781\n",
      "93/93 [==============================] - 7s 77ms/step - loss: -2209.0557 - val_loss: -1893.1853\n",
      "Epoch 338/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2219.4849\n",
      "Epoch 338: val_loss did not improve from -1930.75781\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -2219.4849 - val_loss: -1829.5408\n",
      "Epoch 339/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2192.6575\n",
      "Epoch 339: val_loss improved from -1930.75781 to -1957.70557, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.339-t-2192.66-v-1957.71.hdf5\n",
      "93/93 [==============================] - 8s 84ms/step - loss: -2192.6575 - val_loss: -1957.7056\n",
      "Epoch 340/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -760.0211\n",
      "Epoch 340: val_loss did not improve from -1957.70557\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -760.0211 - val_loss: 1606.1239\n",
      "Epoch 341/500\n",
      "92/93 [============================>.] - ETA: 0s - loss: -502.6567\n",
      "Epoch 341: val_loss did not improve from -1957.70557\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -502.2315 - val_loss: -1138.1406\n",
      "Epoch 342/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1961.2039\n",
      "Epoch 342: val_loss improved from -1957.70557 to -2207.64258, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.342-t-1961.20-v-2207.64.hdf5\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -1961.2039 - val_loss: -2207.6426\n",
      "Epoch 343/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1991.8439\n",
      "Epoch 343: val_loss did not improve from -2207.64258\n",
      "93/93 [==============================] - 8s 80ms/step - loss: -1991.8439 - val_loss: -2155.8533\n",
      "Epoch 344/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1986.3140\n",
      "Epoch 344: val_loss improved from -2207.64258 to -2246.09888, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.344-t-1986.31-v-2246.10.hdf5\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1986.3140 - val_loss: -2246.0989\n",
      "Epoch 345/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1965.1597\n",
      "Epoch 345: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -1965.1597 - val_loss: -1374.5170\n",
      "Epoch 346/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1704.7848\n",
      "Epoch 346: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -1704.7848 - val_loss: -2013.4548\n",
      "Epoch 347/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1476.1840\n",
      "Epoch 347: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -1476.1840 - val_loss: -1905.9714\n",
      "Epoch 348/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1712.8651\n",
      "Epoch 348: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -1712.8651 - val_loss: -961.3148\n",
      "Epoch 349/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1688.0946\n",
      "Epoch 349: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -1688.0946 - val_loss: -1213.4862\n",
      "Epoch 350/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1767.3478\n",
      "Epoch 350: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -1767.3478 - val_loss: -2056.2363\n",
      "Epoch 351/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1953.2803\n",
      "Epoch 351: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -1953.2803 - val_loss: -1530.9536\n",
      "Epoch 352/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1851.7930\n",
      "Epoch 352: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -1851.7930 - val_loss: -2086.3030\n",
      "Epoch 353/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1800.2566\n",
      "Epoch 353: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -1800.2566 - val_loss: -1729.8312\n",
      "Epoch 354/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1849.0195\n",
      "Epoch 354: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1849.0195 - val_loss: -955.8887\n",
      "Epoch 355/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1899.8368\n",
      "Epoch 355: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1899.8368 - val_loss: -1328.6675\n",
      "Epoch 356/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1916.1361\n",
      "Epoch 356: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -1916.1361 - val_loss: -2074.4778\n",
      "Epoch 357/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1826.9171\n",
      "Epoch 357: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1826.9171 - val_loss: -1359.4066\n",
      "Epoch 358/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1825.4978\n",
      "Epoch 358: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -1825.4978 - val_loss: -2090.9409\n",
      "Epoch 359/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2063.1460\n",
      "Epoch 359: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -2063.1460 - val_loss: -1887.6880\n",
      "Epoch 360/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1721.1240\n",
      "Epoch 360: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 77ms/step - loss: -1721.1240 - val_loss: -1918.3278\n",
      "Epoch 361/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2021.8549\n",
      "Epoch 361: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -2021.8549 - val_loss: -2229.7429\n",
      "Epoch 362/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1847.2135\n",
      "Epoch 362: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 77ms/step - loss: -1847.2135 - val_loss: -2196.7222\n",
      "Epoch 363/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1917.8315\n",
      "Epoch 363: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -1917.8315 - val_loss: -83.4958\n",
      "Epoch 364/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1824.2975\n",
      "Epoch 364: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 8s 80ms/step - loss: -1824.2975 - val_loss: -1762.7571\n",
      "Epoch 365/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1892.1447\n",
      "Epoch 365: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -1892.1447 - val_loss: -1886.8549\n",
      "Epoch 366/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2030.9821\n",
      "Epoch 366: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 7s 77ms/step - loss: -2030.9821 - val_loss: -1624.2086\n",
      "Epoch 367/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1996.1931\n",
      "Epoch 367: val_loss did not improve from -2246.09888\n",
      "93/93 [==============================] - 8s 80ms/step - loss: -1996.1931 - val_loss: -1923.2042\n",
      "Epoch 368/500\n",
      "41/93 [============>.................] - ETA: 3s - loss: -2020.5228\n",
      "Epoch 380: val_loss did not improve from -2453.23486\n",
      "93/93 [==============================] - 7s 77ms/step - loss: -2284.2502 - val_loss: -2383.1252\n",
      "Epoch 381/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2272.6316\n",
      "Epoch 381: val_loss did not improve from -2453.23486\n",
      "93/93 [==============================] - 7s 77ms/step - loss: -2272.6316 - val_loss: -2427.0620\n",
      "Epoch 382/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2408.6135\n",
      "Epoch 382: val_loss did not improve from -2453.23486\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -2408.6135 - val_loss: -2291.0552\n",
      "Epoch 383/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2356.8499\n",
      "Epoch 383: val_loss did not improve from -2453.23486\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -2356.8499 - val_loss: -1848.0928\n",
      "Epoch 384/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2342.8020\n",
      "Epoch 384: val_loss did not improve from -2453.23486\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -2342.8020 - val_loss: -2340.1296\n",
      "Epoch 385/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1513.0553\n",
      "Epoch 385: val_loss did not improve from -2453.23486\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -1513.0553 - val_loss: -1161.5685\n",
      "Epoch 386/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2383.9419\n",
      "Epoch 386: val_loss improved from -2453.23486 to -2621.33398, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.386-t-2383.94-v-2621.33.hdf5\n",
      "93/93 [==============================] - 8s 80ms/step - loss: -2383.9419 - val_loss: -2621.3340\n",
      "Epoch 387/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2508.5586\n",
      "Epoch 387: val_loss did not improve from -2621.33398\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -2508.5586 - val_loss: -2328.4453\n",
      "Epoch 388/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2386.5491\n",
      "Epoch 388: val_loss did not improve from -2621.33398\n",
      "93/93 [==============================] - 8s 85ms/step - loss: -2386.5491 - val_loss: -2330.4780\n",
      "Epoch 389/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2017.2695\n",
      "Epoch 389: val_loss did not improve from -2621.33398\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -2017.2695 - val_loss: -2198.8445\n",
      "Epoch 390/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2220.9895\n",
      "Epoch 390: val_loss did not improve from -2621.33398\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -2220.9895 - val_loss: -2121.6033\n",
      "Epoch 391/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2177.7734\n",
      "Epoch 391: val_loss did not improve from -2621.33398\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -2177.7734 - val_loss: -2479.1184\n",
      "Epoch 392/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2122.3828\n",
      "Epoch 392: val_loss did not improve from -2621.33398\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -2122.3828 - val_loss: -694.9916\n",
      "Epoch 393/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2045.6122\n",
      "Epoch 393: val_loss did not improve from -2621.33398\n",
      "93/93 [==============================] - 8s 80ms/step - loss: -2045.6122 - val_loss: -1866.0341\n",
      "Epoch 394/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2105.3135\n",
      "Epoch 394: val_loss improved from -2621.33398 to -2682.20850, saving model to ./trained_models/model-372eef38-3src_MeanFilt3_133eThresh_preDG-checkpoints/weights.394-t-2105.31-v-2682.21.hdf5\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -2105.3135 - val_loss: -2682.2085\n",
      "Epoch 395/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2099.4778\n",
      "Epoch 395: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -2099.4778 - val_loss: -2279.0771\n",
      "Epoch 396/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2131.2380\n",
      "Epoch 396: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 77ms/step - loss: -2131.2380 - val_loss: -2291.0007\n",
      "Epoch 397/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2210.3459\n",
      "Epoch 397: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -2210.3459 - val_loss: -1884.8282\n",
      "Epoch 398/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1940.8773\n",
      "Epoch 398: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 77ms/step - loss: -1940.8773 - val_loss: -2193.5564\n",
      "Epoch 399/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2150.1284\n",
      "Epoch 399: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -2150.1284 - val_loss: -2101.7078\n",
      "Epoch 400/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2120.0984\n",
      "Epoch 400: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -2120.0984 - val_loss: -1483.8240\n",
      "Epoch 401/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -1980.3740\n",
      "Epoch 401: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 8s 81ms/step - loss: -1980.3740 - val_loss: -1771.7902\n",
      "Epoch 402/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2035.7991\n",
      "Epoch 402: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -2035.7991 - val_loss: -2136.4678\n",
      "Epoch 403/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2016.2859\n",
      "Epoch 403: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -2016.2859 - val_loss: -2230.0049\n",
      "Epoch 404/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2127.0920\n",
      "Epoch 404: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 8s 82ms/step - loss: -2127.0920 - val_loss: -2102.3425\n",
      "Epoch 405/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2180.8662\n",
      "Epoch 405: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 76ms/step - loss: -2180.8662 - val_loss: -2061.5303\n",
      "Epoch 406/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2205.4011\n",
      "Epoch 406: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -2205.4011 - val_loss: -2309.1392\n",
      "Epoch 407/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2062.9937\n",
      "Epoch 407: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -2062.9937 - val_loss: -2668.9185\n",
      "Epoch 408/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2221.4924\n",
      "Epoch 408: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -2221.4924 - val_loss: -2069.2427\n",
      "Epoch 409/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2265.0801\n",
      "Epoch 409: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -2265.0801 - val_loss: -2630.1687\n",
      "Epoch 410/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2206.4470\n",
      "Epoch 410: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -2206.4470 - val_loss: -2044.4661\n",
      "Epoch 411/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2036.5164\n",
      "Epoch 411: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -2036.5164 - val_loss: -2121.0591\n",
      "Epoch 412/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2221.3938\n",
      "Epoch 412: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -2221.3938 - val_loss: -2083.4414\n",
      "Epoch 413/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2293.9548\n",
      "Epoch 413: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 78ms/step - loss: -2293.9548 - val_loss: -2112.9272\n",
      "Epoch 414/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2401.1182\n",
      "Epoch 414: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 8s 80ms/step - loss: -2401.1182 - val_loss: -2089.6382\n",
      "Epoch 415/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2386.7288\n",
      "Epoch 415: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -2386.7288 - val_loss: -1922.1044\n",
      "Epoch 416/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2274.2188\n",
      "Epoch 416: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 79ms/step - loss: -2274.2188 - val_loss: -2463.3906\n",
      "Epoch 417/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2536.2124\n",
      "Epoch 417: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 8s 83ms/step - loss: -2536.2124 - val_loss: -2419.4697\n",
      "Epoch 418/500\n",
      "93/93 [==============================] - ETA: 0s - loss: -2524.7637\n",
      "Epoch 418: val_loss did not improve from -2682.20850\n",
      "93/93 [==============================] - 7s 80ms/step - loss: -2524.7637 - val_loss: -1625.9172\n",
      "Epoch 419/500\n",
      "65/93 [===================>..........] - ETA: 1s - loss: -2589.4055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        x=training_generator,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[es, mcp, csv_logger],\n",
    "        epochs=500,\n",
    "        shuffle=False,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e2706-3e27-4ece-9ebd-be135f6bbcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bbe74d-28b5-4c89-969b-224ee9ef71f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112416ce-8c0b-43bf-9957-c4c365f396e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-myenv]",
   "language": "python",
   "name": "conda-env-.conda-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
